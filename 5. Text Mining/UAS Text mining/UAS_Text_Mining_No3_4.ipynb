{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54yKHOtvKqEG"
      },
      "source": [
        "**Nama:** Devin Augustin\n",
        "\n",
        "**NIM:** 2440094352"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWQvItgoL-HT"
      },
      "outputs": [],
      "source": [
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzd849-zO9vX"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihd9mEQYxi1z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import re, string\n",
        "from unidecode import unidecode\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF9voFDVBpTI"
      },
      "source": [
        "#**Jawaban Nomor 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fblxosPuB58H"
      },
      "source": [
        "Diberikan suatu data teks yang berisi abstrak dari beberapa artikel (data_3-.csv),\n",
        "Anda ingin mengelompokan topik dari abstrak-abstrak ini, namun anda belum memiliki label untuk setiap\n",
        "abstraknya. Anda perlu menggunakan pendekatan yang tidak memerlukan label.Tentukan topik dari\n",
        "abstrak tersebut dengan menggunakan data yang ada, lakukan eksperimen dengan beberapa jumlah topik,\n",
        "lakukan analisa berdasarkan coherence score dan persona analysis terhadap beberapa sampel. Jelaskan\n",
        "analisa anda!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTPgeS-tBsOk"
      },
      "outputs": [],
      "source": [
        "df3 = pd.read_csv(\"/content/data_3C.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PuWNC0ZJXvYu",
        "outputId": "ecb18a40-c340-419a-9af3-078017c83d71"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c97066c6-a402-46ba-b365-6165df116734\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ABSTRACT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>200</td>\n",
              "      <td>The topological morphology--order of zeros a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>201</td>\n",
              "      <td>The purpose of this paper is to formulate an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>202</td>\n",
              "      <td>This paper considers the problem of autonomo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>203</td>\n",
              "      <td>This study explores the validity of chain ef...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>204</td>\n",
              "      <td>Developing neural network image classificati...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c97066c6-a402-46ba-b365-6165df116734')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c97066c6-a402-46ba-b365-6165df116734 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c97066c6-a402-46ba-b365-6165df116734');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0                                           ABSTRACT\n",
              "0         200    The topological morphology--order of zeros a...\n",
              "1         201    The purpose of this paper is to formulate an...\n",
              "2         202    This paper considers the problem of autonomo...\n",
              "3         203    This study explores the validity of chain ef...\n",
              "4         204    Developing neural network image classificati..."
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OWG3P20JKhPq",
        "outputId": "2d0c1c64-b14e-4f95-a033-485de47acca2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a8c29140-6ae0-4077-aad1-46acac1ae1b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ABSTRACT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The topological morphology--order of zeros a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The purpose of this paper is to formulate an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This paper considers the problem of autonomo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This study explores the validity of chain ef...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Developing neural network image classificati...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8c29140-6ae0-4077-aad1-46acac1ae1b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8c29140-6ae0-4077-aad1-46acac1ae1b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8c29140-6ae0-4077-aad1-46acac1ae1b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            ABSTRACT\n",
              "0    The topological morphology--order of zeros a...\n",
              "1    The purpose of this paper is to formulate an...\n",
              "2    This paper considers the problem of autonomo...\n",
              "3    This study explores the validity of chain ef...\n",
              "4    Developing neural network image classificati..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "df3.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f30FKrzdLwP_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rkxHeWRzwRB"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bi19yeRmzvi8"
      },
      "outputs": [],
      "source": [
        "def cleansing(df):\n",
        "    df_clean=df.str.lower() #mengubah semua teks menjadi huruf kecil\n",
        "    df_clean=[re.sub(r\"\\d+\",\"\",i )for i in df_clean] #menghapus digit apa pun dalam teks dengan menggantinya dengan string kosong\n",
        "    df_clean=[re.sub(r'[^\\w]', ' ', i)for i in df_clean] #menghapus karakter non-alphanumeric dengan menggantinya dengan spasi\n",
        "    df_clean=[re.sub(r'\\s+',' ',i)for i in df_clean] #menghilangkan spasi ekstra dengan mengganti beberapa spasi berturut-turut dengan satu spasi\n",
        "    df_clean = [unidecode(i) for i in df_clean] #menghilangkan huruf yang memiliki aksen\n",
        "    df_clean = [re.sub(r'[^a-zA-Z\\s]', '', i) for i in df_clean] #menghilangkan non-english alphabet\n",
        "    return df_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5lcZa-e0Qhq"
      },
      "outputs": [],
      "source": [
        "clean_text = cleansing(df3['ABSTRACT']) #memanggil function 'cleansing' dengan menggunakan data kolom 'text' dari df dan mengembalikkan nilainya ke dalam variable 'clean_text'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8S_aUJJ0Yaf",
        "outputId": "bf67278b-c8e9-4e28-c299-d05e162f7cc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[' the topological morphology order of zeros at the positions of electrons with respect to a specific electron of laughlin state at filling fractions m m odd is homogeneous as every electron feels zeros of order m at the positions of other electrons although fairly accurate ground state wave functions for most of the other quantum hall states in the lowest landau level are quite well known it had been an open problem in expressing the ground state wave functions in terms of flux attachment to particles em a la this morphology of laughlin state with a very general consideration of flux particle relations only in spherical geometry we here report a novel method for determining morphologies of these states based on these we construct almost exact ground state wave functions for the coulomb interaction although the form of interaction may change the ground state wave function the same morphology constructs the latter irrespective of the nature of the interaction between electrons ',\n",
              " ' the purpose of this paper is to formulate and study a common refinement of a version of stark s conjecture and its p adic analogue in terms of fontaine s p adic period ring and p adic hodge theory we construct period ring valued functions under a generalization of yoshida s conjecture on the transcendental parts of cm periods then we conjecture a reciprocity law on their special values concerning the absolute frobenius action we show that our conjecture implies a part of stark s conjecture when the base field is an arbitrary real field and the splitting place is its real place it also implies a refinement of the gross stark conjecture under a certain assumption when the base field is the rational number field our conjecture follows from coleman s formula on fermat curves we also prove some partial results in other cases ',\n",
              " ' this paper considers the problem of autonomous multi agent cooperative target search in an unknown environment using a decentralized framework under a no communication scenario the targets are considered as static targets and the agents are considered to be homogeneous the no communication scenario translates as the agents do not exchange either the information about the environment or their actions among themselves we propose an integrated decision and control theoretic solution for a search problem which generates feasible agent trajectories in particular a perception based algorithm is proposed which allows an agent to estimate the probable strategies of other agents and to choose a decision based on such estimation the algorithm shows robustness with respect to the estimation accuracy to a certain degree the performance of the algorithm is compared with random strategies and numerical simulation shows considerable advantages ',\n",
              " ' this study explores the validity of chain effects of clean water which are known as the mills reincke phenomenon in early twentieth century japan recent studies have reported that water purifications systems are responsible for huge contributions to human capital although a few studies have investigated the short term effects of water supply systems in pre war japan little is known about the benefits associated with these systems by analyzing city level cause specific mortality data from the years we found that eliminating typhoid fever infections decreased the risk of deaths due to non waterborne diseases our estimates show that for one additional typhoid death there were approximately one to three deaths due to other causes such as tuberculosis and pneumonia this suggests that the observed mills reincke phenomenon could have resulted from the prevention typhoid fever in a previously developing asian country ',\n",
              " ' developing neural network image classification models often requires significant architecture engineering in this paper we study a method to learn the model architectures directly on the dataset of interest as this approach is expensive when the dataset is large we propose to search for an architectural building block on a small dataset and then transfer the block to a larger dataset the key contribution of this work is the design of a new search space the nasnet search space which enables transferability in our experiments we search for the best convolutional layer or cell on the cifar dataset and then apply this cell to the imagenet dataset by stacking together more copies of this cell each with their own parameters to design a convolutional architecture named nasnet architecture we also introduce a new regularization technique called scheduleddroppath that significantly improves generalization in the nasnet models on cifar itself nasnet achieves error rate which is state of the art on imagenet nasnet achieves among the published works state of the art accuracy of top and top on imagenet our model is better in top accuracy than the best human invented architectures while having billion fewer flops a reduction of in computational demand from the previous state of the art model when evaluated at different levels of computational cost accuracies of nasnets exceed those of the state of the art human designed models for instance a small version of nasnet also achieves top accuracy which is better than equivalently sized state of the art models for mobile platforms finally the learned features by nasnet used with the faster rcnn framework surpass state of the art by achieving map on the coco dataset ']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_text[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1b0t9oz5AcL"
      },
      "outputs": [],
      "source": [
        "#Tokenization\n",
        "#Tokenization adalah proses memecah teks menjadi unit yang lebih kecil, seperti kata atau kalimat\n",
        "word_list = [sentence.split() for sentence in clean_text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PPhZ3824OZD",
        "outputId": "a2ddac1f-d098-4bcc-ac74-5ccffa50bc3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Remove Stopwords\n",
        "#Menghapus stopwords mengacu pada proses menghilangkan kata-kata umum (seperti \"the\", \"is\", \"and\") dari teks\n",
        "#yang dianggap tidak penting untuk analisis atau tidak berkontribusi banyak pada keseluruhan makna.\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "list_stopwords=set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qh10Vwwh2d0C"
      },
      "outputs": [],
      "source": [
        "token_clean =[[word for word in sentence if not word in list_stopwords] for sentence in word_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjv6wlL56TJe",
        "outputId": "58de3a1e-21d1-41cc-ff19-6ebc165e2c1b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Lemmatization\n",
        "#Lemmatisasi adalah proses mereduksi kata menjadi bentuk dasarnya atau kamus (lemma) untuk mencapai analisis dan pemahaman teks yang lebih baik.\n",
        "from nltk import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "final_token = [[lemmatizer.lemmatize(word) for word in sentence] for sentence in token_clean]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHrvPgTz8mBd",
        "outputId": "d9ecf0eb-8f05-4ac6-adfb-1b078d091c8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['topological',\n",
              " 'morphology',\n",
              " 'order',\n",
              " 'zero',\n",
              " 'position',\n",
              " 'electron',\n",
              " 'respect',\n",
              " 'specific',\n",
              " 'electron',\n",
              " 'laughlin',\n",
              " 'state',\n",
              " 'filling',\n",
              " 'fraction',\n",
              " 'odd',\n",
              " 'homogeneous',\n",
              " 'every',\n",
              " 'electron',\n",
              " 'feel',\n",
              " 'zero',\n",
              " 'order',\n",
              " 'position',\n",
              " 'electron',\n",
              " 'although',\n",
              " 'fairly',\n",
              " 'accurate',\n",
              " 'ground',\n",
              " 'state',\n",
              " 'wave',\n",
              " 'function',\n",
              " 'quantum',\n",
              " 'hall',\n",
              " 'state',\n",
              " 'lowest',\n",
              " 'landau',\n",
              " 'level',\n",
              " 'quite',\n",
              " 'well',\n",
              " 'known',\n",
              " 'open',\n",
              " 'problem',\n",
              " 'expressing',\n",
              " 'ground',\n",
              " 'state',\n",
              " 'wave',\n",
              " 'function',\n",
              " 'term',\n",
              " 'flux',\n",
              " 'attachment',\n",
              " 'particle',\n",
              " 'em',\n",
              " 'la',\n",
              " 'morphology',\n",
              " 'laughlin',\n",
              " 'state',\n",
              " 'general',\n",
              " 'consideration',\n",
              " 'flux',\n",
              " 'particle',\n",
              " 'relation',\n",
              " 'spherical',\n",
              " 'geometry',\n",
              " 'report',\n",
              " 'novel',\n",
              " 'method',\n",
              " 'determining',\n",
              " 'morphology',\n",
              " 'state',\n",
              " 'based',\n",
              " 'construct',\n",
              " 'almost',\n",
              " 'exact',\n",
              " 'ground',\n",
              " 'state',\n",
              " 'wave',\n",
              " 'function',\n",
              " 'coulomb',\n",
              " 'interaction',\n",
              " 'although',\n",
              " 'form',\n",
              " 'interaction',\n",
              " 'may',\n",
              " 'change',\n",
              " 'ground',\n",
              " 'state',\n",
              " 'wave',\n",
              " 'function',\n",
              " 'morphology',\n",
              " 'construct',\n",
              " 'latter',\n",
              " 'irrespective',\n",
              " 'nature',\n",
              " 'interaction',\n",
              " 'electron']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_token[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XZuJfJfakWv"
      },
      "source": [
        "**Build Dictionary**\n",
        "\n",
        "*Building dictionary* untuk *topic prediction* melibatkan pembuatan daftar kata atau frasa penting yang terkait dengan berbagai topik. Dengan menganalisis contoh teks dan menghitung frekuensi kata, kami memilih kata yang paling umum untuk setiap topik. Kata-kata ini membentuk kamus, dan ketika diterapkan pada teks baru, kita dapat memprediksi topik berdasarkan keberadaan kata kunci tersebut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0DWMY8PcEQI"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import CoherenceModel\n",
        "from gensim import corpora, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGxY6d3yaiOf"
      },
      "outputs": [],
      "source": [
        "#Membangun dictionary berdasarkan teks yang diberikan. Kamus ini akan digunakan untuk memetakan kata-kata dalam teks menjadi representasi numerik, seperti indeks atau ID kata-kata.d\n",
        "def build_dic(text):\n",
        "    dictionary = Dictionary(text)\n",
        "    dictionary.filter_extremes(no_below=1, no_above=0.2, keep_n= 100000)\n",
        "    return dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdxVcyHkM30z",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "dictionary=build_dic(final_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJsm15F6cBvZ"
      },
      "outputs": [],
      "source": [
        "#Membangun vektor Bag of Words corpus berdasarkan teks yang diberikan dan kamus yang telah dibangun sebelumnya.\n",
        "def build_vec(text,dictionary):\n",
        "    bow_corpus = [dictionary.doc2bow(doc) for doc in text]\n",
        "    return bow_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Zkm-jx3M30z"
      },
      "outputs": [],
      "source": [
        "bow_corpus=build_vec(final_token,dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Y14KJBbcI5B"
      },
      "outputs": [],
      "source": [
        "#Menghitung score TF-IDF dari bag of words\n",
        "def vector_tfidf(bow_corpus):\n",
        "    tfidf = models.TfidfModel(bow_corpus)\n",
        "    corpus_tfidf = tfidf[bow_corpus]\n",
        "    return corpus_tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHd0HDLTM30z"
      },
      "outputs": [],
      "source": [
        "corpus_tfidf=vector_tfidf(bow_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GklzAokycRmD"
      },
      "outputs": [],
      "source": [
        "#membangun model LDA untuk mengidentifikasi topik-topik yang ada dalam dokumen dan mendistribusikan kata-kata ke dalam topik-topik tersebut.\n",
        "def model_lda(dictionary,bow_corpus,num_topic,alpha,eta):\n",
        "    lda_model =  gensim.models.LdaMulticore(bow_corpus,\n",
        "                                   num_topics = num_topic,\n",
        "                                   id2word = dictionary,\n",
        "                                   passes = 10,\n",
        "                                   workers = 2,\n",
        "                                   alpha=alpha,\n",
        "                                   eta=eta)\n",
        "    return lda_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ET-EuPG4M30z"
      },
      "outputs": [],
      "source": [
        "lda_model=model_lda(dictionary,corpus_tfidf,4,0.7,0.7) #Disini mari kita coba menggunakan 4 jumlah topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57oi38AHcSAS"
      },
      "outputs": [],
      "source": [
        "#Fungsi untuk menemukan coherence score\n",
        "#Coherence score digunakan untuk mengukur kualitas dan interpretabilitas topik yang dihasilkan oleh model pemodelan topik\n",
        "def score_perf(lda_model,text,dictionary):\n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=text, dictionary=dictionary, coherence='c_v')\n",
        "    coherence_lda = coherence_model_lda.get_coherence()\n",
        "    return coherence_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBuTyy0MM300"
      },
      "outputs": [],
      "source": [
        "coherence_score=score_perf(lda_model,final_token,dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZPsFai0M300",
        "outputId": "af26f70b-01fc-4d46-f99f-d10d1fa76a8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4928106611687548\n"
          ]
        }
      ],
      "source": [
        "print(coherence_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abg8ROehRPbO"
      },
      "source": [
        "Coherence score yang lebih tinggi menunjukkan bahwa kata-kata dalam suatu topik terkait lebih kuat dan koheren. Ini menunjukkan bahwa topiknya lebih dapat ditafsirkan dan mewakili tema yang berbeda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPE8qWa_M300",
        "outputId": "51136c16-94aa-4ed6-ab67-9e505f50588e",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "Words: 0.000*\"algorithm\" + 0.000*\"distribution\" + 0.000*\"q\" + 0.000*\"network\" + 0.000*\"state\" + 0.000*\"class\" + 0.000*\"architecture\" + 0.000*\"image\" + 0.000*\"quantum\" + 0.000*\"matrix\"\n",
            "\n",
            "\n",
            "Topic: 1 \n",
            "Words: 0.000*\"algorithm\" + 0.000*\"distribution\" + 0.000*\"network\" + 0.000*\"q\" + 0.000*\"quantum\" + 0.000*\"set\" + 0.000*\"matrix\" + 0.000*\"music\" + 0.000*\"state\" + 0.000*\"class\"\n",
            "\n",
            "\n",
            "Topic: 2 \n",
            "Words: 0.000*\"quantum\" + 0.000*\"algorithm\" + 0.000*\"distribution\" + 0.000*\"q\" + 0.000*\"network\" + 0.000*\"state\" + 0.000*\"music\" + 0.000*\"code\" + 0.000*\"set\" + 0.000*\"theorem\"\n",
            "\n",
            "\n",
            "Topic: 3 \n",
            "Words: 0.001*\"distribution\" + 0.000*\"algorithm\" + 0.000*\"network\" + 0.000*\"matrix\" + 0.000*\"state\" + 0.000*\"quantum\" + 0.000*\"structure\" + 0.000*\"function\" + 0.000*\"class\" + 0.000*\"set\"\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Fungsi untuk mencetak topik-topik yang dihasilkan oleh model LDA beserta kata-kata yang termasuk dalam setiap topik.\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z46I4fhKSNX4"
      },
      "source": [
        "Setiap baris output menunjukkan informasi tentang satu topik. Kata-kata yang muncul setelah tanda \"*\" adalah kata-kata yang paling berkontribusi dalam membentuk topik tersebut, dan angka yang mengikuti kata-kata tersebut adalah bobotnya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8w3FueFcTL_"
      },
      "outputs": [],
      "source": [
        "#Melakukan cleansing terhadap data pada kolom 'ABSTRACT'\n",
        "data_cleantest=cleansing(df3['ABSTRACT'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYP5i5HmM301"
      },
      "outputs": [],
      "source": [
        "#Melakukan inferensi topik pada data menggunakan model LDA yang telah dilatih sebelumnya.\n",
        "#Iterasi dilakukan melalui setiap dokumen dalam data dan untuk setiap dokumen, topik yang paling relevan dan kedua paling relevan ditentukan dengan memperhatikan skor probabilitasnya.\n",
        "test_shape=len(data_cleantest)\n",
        "topic1=[]\n",
        "score1=[]\n",
        "topic2=[]\n",
        "score2=[]\n",
        "sentence=[]\n",
        "for doc in range(test_shape):\n",
        "    sentence.append(data_cleantest[doc])\n",
        "    topic1.append(sorted(lda_model[bow_corpus[doc]], key=lambda tup: -1*tup[1])[0][0])\n",
        "    score1.append(sorted(lda_model[bow_corpus[doc]], key=lambda tup: -1*tup[1])[0][1])\n",
        "    topic2.append(sorted(lda_model[bow_corpus[doc]], key=lambda tup: -1*tup[1])[1][0])\n",
        "    score2.append(sorted(lda_model[bow_corpus[doc]], key=lambda tup: -1*tup[1])[1][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0S-7Cm4M301"
      },
      "outputs": [],
      "source": [
        "#Menggabungkan hasil inferensi topik dan skor probabilitasnya ke dalam satu DataFrame\n",
        "sentence=pd.DataFrame(sentence,columns=['sentence']).reset_index()\n",
        "topic1=pd.DataFrame(topic1,columns=['topic1']).reset_index()\n",
        "score1=pd.DataFrame(score1,columns=['score1']).reset_index()\n",
        "topic2=pd.DataFrame(topic2,columns=['topic2']).reset_index()\n",
        "score2=pd.DataFrame(score2,columns=['score2']).reset_index()\n",
        "test_result=pd.concat([sentence,topic1,score1,topic2,score2],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "d16oDIfBM301",
        "outputId": "01bbeac6-2fb8-45fe-a083-24052a6cefd0",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0ae93625-bf18-4b27-b7f1-d43485eb7001\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>topic1</th>\n",
              "      <th>score1</th>\n",
              "      <th>topic2</th>\n",
              "      <th>score2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the topological morphology order of zeros at ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.357501</td>\n",
              "      <td>3</td>\n",
              "      <td>0.322040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the purpose of this paper is to formulate and...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.347985</td>\n",
              "      <td>2</td>\n",
              "      <td>0.258408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>this paper considers the problem of autonomou...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.308258</td>\n",
              "      <td>1</td>\n",
              "      <td>0.240056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this study explores the validity of chain eff...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.268768</td>\n",
              "      <td>0</td>\n",
              "      <td>0.268615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>developing neural network image classificatio...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.376399</td>\n",
              "      <td>0</td>\n",
              "      <td>0.245255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>we propose a new multi frame method for effic...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.497046</td>\n",
              "      <td>3</td>\n",
              "      <td>0.184000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>let k be an algebraically closed field of pos...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.296733</td>\n",
              "      <td>1</td>\n",
              "      <td>0.264872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>we present the mixed galerkin discretization ...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.360869</td>\n",
              "      <td>1</td>\n",
              "      <td>0.246296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>the regularity of earthquakes their destructi...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.366661</td>\n",
              "      <td>2</td>\n",
              "      <td>0.254459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>in this paper we prove some difference analog...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.381611</td>\n",
              "      <td>1</td>\n",
              "      <td>0.288674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>large scale datasets have played a significan...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.279326</td>\n",
              "      <td>0</td>\n",
              "      <td>0.214206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>observational data collected during experimen...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.349323</td>\n",
              "      <td>2</td>\n",
              "      <td>0.254136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>for a knot k in a homology sphere sigma let m...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410914</td>\n",
              "      <td>0</td>\n",
              "      <td>0.240366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>sparse feature selection is necessary when we...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.283382</td>\n",
              "      <td>2</td>\n",
              "      <td>0.276869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>in this letter we consider the joint power an...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.289834</td>\n",
              "      <td>1</td>\n",
              "      <td>0.260023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>a rosat survey of the alpha per open cluster ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.326757</td>\n",
              "      <td>2</td>\n",
              "      <td>0.250996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>realistic music generation is a challenging t...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.330651</td>\n",
              "      <td>0</td>\n",
              "      <td>0.230752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>young asteroid families are unique sources of...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.415093</td>\n",
              "      <td>2</td>\n",
              "      <td>0.197845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>we provide a graph formula which describes an...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.332038</td>\n",
              "      <td>0</td>\n",
              "      <td>0.279576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>tomography has made a radical impact on diver...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.361384</td>\n",
              "      <td>3</td>\n",
              "      <td>0.255333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ae93625-bf18-4b27-b7f1-d43485eb7001')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ae93625-bf18-4b27-b7f1-d43485eb7001 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ae93625-bf18-4b27-b7f1-d43485eb7001');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             sentence  topic1    score1  \\\n",
              "0    the topological morphology order of zeros at ...       2  0.357501   \n",
              "1    the purpose of this paper is to formulate and...       1  0.347985   \n",
              "2    this paper considers the problem of autonomou...       3  0.308258   \n",
              "3    this study explores the validity of chain eff...       0  0.268768   \n",
              "4    developing neural network image classificatio...       0  0.376399   \n",
              "5    we propose a new multi frame method for effic...       0  0.497046   \n",
              "6    let k be an algebraically closed field of pos...       2  0.296733   \n",
              "7    we present the mixed galerkin discretization ...       3  0.360869   \n",
              "8    the regularity of earthquakes their destructi...       3  0.366661   \n",
              "9    in this paper we prove some difference analog...       2  0.381611   \n",
              "10   large scale datasets have played a significan...       2  0.279326   \n",
              "11   observational data collected during experimen...       3  0.349323   \n",
              "12   for a knot k in a homology sphere sigma let m...       2  0.410914   \n",
              "13   sparse feature selection is necessary when we...       1  0.283382   \n",
              "14   in this letter we consider the joint power an...       3  0.289834   \n",
              "15   a rosat survey of the alpha per open cluster ...       0  0.326757   \n",
              "16   realistic music generation is a challenging t...       2  0.330651   \n",
              "17   young asteroid families are unique sources of...       3  0.415093   \n",
              "18   we provide a graph formula which describes an...       3  0.332038   \n",
              "19   tomography has made a radical impact on diver...       3  0.361384   \n",
              "\n",
              "    topic2    score2  \n",
              "0        3  0.322040  \n",
              "1        2  0.258408  \n",
              "2        1  0.240056  \n",
              "3        0  0.268615  \n",
              "4        0  0.245255  \n",
              "5        3  0.184000  \n",
              "6        1  0.264872  \n",
              "7        1  0.246296  \n",
              "8        2  0.254459  \n",
              "9        1  0.288674  \n",
              "10       0  0.214206  \n",
              "11       2  0.254136  \n",
              "12       0  0.240366  \n",
              "13       2  0.276869  \n",
              "14       1  0.260023  \n",
              "15       2  0.250996  \n",
              "16       0  0.230752  \n",
              "17       2  0.197845  \n",
              "18       0  0.279576  \n",
              "19       3  0.255333  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Menunjukkan 20 hasil pertama\n",
        "test_result=test_result[['sentence','topic1','score1','topic2','score2']]\n",
        "test_result.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4Xy7XonBsV6"
      },
      "source": [
        "#**Jawaban Nomor 4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCFrkxvsB7u-"
      },
      "source": [
        "Anda memiliki suatu teks (data.4-.txt) yang ingin anda simpulkan dengan\n",
        "bantuan algoritma. Lakukanlah pemodelan text summarization menggunakan pendekatan extractive\n",
        "dengan menggunakan top 3 scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGogviF49MOz"
      },
      "outputs": [],
      "source": [
        "from nltk.cluster.util import cosine_distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TUDV2v48xZl"
      },
      "outputs": [],
      "source": [
        "#Fungsi untuk membaca file\n",
        "def read_article(file_name):\n",
        "    file = open(file_name, \"r\")\n",
        "    filedata = file.readlines()\n",
        "    #memisahkan kalimat berdasarkan pemisah titik (.).\n",
        "    article = filedata[0].split(\". \")\n",
        "    sentences = []\n",
        "    for sentence in article:\n",
        "        print(sentence)\n",
        "        #menghapus karakter non alfabet\n",
        "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
        "    sentences.pop()\n",
        "\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Hts6EBJAj6P",
        "outputId": "a55facd3-e98e-4432-a919-a95de92ef26a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The transfer of vocational education and training (VET) systems is currently an important topic in international debates (Davoine and Deitmer Citation2020; Maurer and Gonon Citation2014a; Valiente and Scandurra Citation2017; Allais Citation2010; King Citation2014; McGrath Citation2002)\n",
            "The reasons given for policy transfer in the VET sector are complex and include aspects like (youth) unemployment reduction, poverty reduction, equipping skilled workers and increasing economic growth (Wiriadidjaja, Andriasanti, and Jane Citation2019; Stockmann Citation2019; France Diplomacy Citation2019; Bank et al\n",
            "Citation2015)\n",
            "However, surprisingly little recent research has explored issues such as practicability, successes achieved, problems encountered, and long-term effects\n",
            "Scholars are more likely to focus on the theoretical basis for training transfer (Dolowitz and Marsh Citation2000), or on options for transfer at a more intermediate level of abstraction (Gonon Citation2014)\n",
            "Policy transfer can be defined in various ways, and this can be confusing  partly due to the nuances involved of policy transfer, and partly due to the fact that different definitions have emerged within different academic disciplines\n",
            "For example, the terms policy learning and policy transfer are used in political science, while policy diffusion and policy reception are used in sociology, social anthropology, and historical studies\n",
            "The terms policy borrowing and policy lending originated in the comparative educational sciences (Finegold et al\n",
            "Citation1993; Steiner-Khamsi Citation2012)\n",
            "Terms such as transfer, export, and policy borrowing or learning are also imprecisely defined or controversial, partly because different disciplines use different metaphors for the policy transfer process\n",
            "Policy transfer is commonly used in the international and interdisciplinary context: this term covers the transfer of education, but it also implies the transfer of procedures, measures, strategies, and concepts in the broadest sense (Rose Citation1991)\n",
            "The following discussion is not limited to a narrow conceptualisation of policy at the systemic level; it also focuses on micro-political transfer activities that are highly relevant to VET\n",
            "It will build on Hulmes (Citation2005) ideas about the movement of ideas and practices and apply the term policy in its broadest sense.Footnote1 It will demonstrate that policy transfer as it relates to VETFootnote2 is not the exclusive domain of scholars working in international comparative VET research; it is related to work being conducted in various disciplines and from different perspectives\n",
            "However, scholars working in all disciplines are guided by the same basic questions related to the dimensions of the motives of the transfer, the actors involved, the transfer process, the object of the transfer and the degree of success of the transfer (e.g\n",
            "Rahimi and Smith Citation2017)\n",
            "In other words, what is transferred, how, and with what results, and which factors are decisive? This literature review synthesises the findings from different disciplines, exploring differences and similarities; the results provide important lessons for scholars working in comparative vocational training research\n",
            "We have selected a narrative approach to investigate this complex topic (Ferrari Citation2015)\n",
            "This technique is particularly useful in this context because it can incorporate literature from different countries and different languages in appropriate and meaningful ways, despite the different terminology used (Hammersley Citation2006)\n",
            "This extensive literature review includes contributions from scientific journals, anthologies, and monographs from recognised institutions\n",
            "It does not include project reports or other reports on single implementation at the micro-level, because they have little value in terms of scientific generalisation\n",
            "We searched electronic databases, and also conducted research in libraries and by applying a snowballing strategy, to find research published in English and also German, due to the special importance of the topic in German-speaking countries (e.g\n",
            "iMove Citation2020)\n",
            "We have included theoretical and conceptual contributions, as well as empirical studies on policy transfer\n",
            "All publications were assessed for quality, including the standards of scientific work, such as the review process, quality of citation, etc\n",
            "Relevant themes were identified using inductive category formation\n",
            "The next sections introduce policy transfer research from various disciplines\n",
            "Each discipline is discussed separately  first by outlining the specific focus of each discipline, followed by an exploration of the relevant theoretical, conceptual and empirical results\n",
            "Finally, we synthesise the results from all disciplines to derive conclusions and possible directions for future research.\n"
          ]
        }
      ],
      "source": [
        "text = read_article('data_4C.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGiOH5tU8xZl"
      },
      "outputs": [],
      "source": [
        "#Fungsi untuk menghitung tingkat kemiripan antara dua kalimat berdasarkan vektorisasi kata-kata yang ada dalam kalimat tersebut.\n",
        "def sentence_similarity(sent1, sent2, stopwords=None):\n",
        "    if stopwords is None:\n",
        "        stopwords = []\n",
        "\n",
        "    sent1 = [w.lower() for w in sent1]\n",
        "    sent2 = [w.lower() for w in sent2]\n",
        "\n",
        "    all_words = list(set(sent1 + sent2))\n",
        "\n",
        "    #Membangun vektor 0 dengan dimensi mengikuti len dari all_words\n",
        "    vector1 = [0] * len(all_words)\n",
        "    vector2 = [0] * len(all_words)\n",
        "\n",
        "    #Membangun vektor untuk kalimat pertama\n",
        "    for w in sent1:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector1[all_words.index(w)] += 1\n",
        "\n",
        "    #Membangun vektor untuk kalimat kedua\n",
        "    for w in sent2:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector2[all_words.index(w)] += 1\n",
        "\n",
        "    return 1 - cosine_distance(vector1, vector2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK708vBz8xZm"
      },
      "outputs": [],
      "source": [
        "#Fungsi untuk membangun matriks kemiripan antara kalimat-kalimat dalam suatu daftar.\n",
        "def build_similarity_matrix(sentences, stop_words):\n",
        "    #Membuat similarity matrix kosong\n",
        "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
        "\n",
        "    for idx1 in range(len(sentences)):\n",
        "        for idx2 in range(len(sentences)):\n",
        "            if idx1 == idx2: #abaikan jika kalimat sama\n",
        "                continue\n",
        "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
        "\n",
        "    return similarity_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dhsi76MAAzb0",
        "outputId": "423976a3-3d42-4e72-85f0-93fff7e2e62e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.03005565, 0.        , 0.        , 0.13245324,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.04012862,\n",
              "        0.14547859, 0.04811252, 0.06600984, 0.11111111, 0.        ,\n",
              "        0.11547005, 0.06804138, 0.        , 0.        , 0.        ,\n",
              "        0.03703704, 0.        , 0.06415003, 0.        , 0.        ,\n",
              "        0.06804138, 0.        ],\n",
              "       [0.03005565, 0.        , 0.        , 0.        , 0.07165744,\n",
              "        0.05609927, 0.        , 0.08347839, 0.        , 0.09769344,\n",
              "        0.11805627, 0.11713032, 0.08035074, 0.09016696, 0.        ,\n",
              "        0.        , 0.05521576, 0.        , 0.        , 0.04173919,\n",
              "        0.        , 0.        , 0.10411584, 0.        , 0.        ,\n",
              "        0.11043153, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.35355339, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.05143445, 0.        ,\n",
              "        0.05345225, 0.        , 0.        , 0.        , 0.07142857,\n",
              "        0.1028689 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.09449112, 0.        ],\n",
              "       [0.13245324, 0.07165744, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.09567297,\n",
              "        0.26013299, 0.11470787, 0.11803342, 0.30905755, 0.        ,\n",
              "        0.09176629, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.22941573, 0.        , 0.        ,\n",
              "        0.16222142, 0.05735393],\n",
              "       [0.        , 0.05609927, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.03126527, 0.        , 0.        , 0.48685383,\n",
              "        0.06788442, 0.08980265, 0.18481233, 0.06913011, 0.        ,\n",
              "        0.07184212, 0.        , 0.25144742, 0.        , 0.        ,\n",
              "        0.06913011, 0.        , 0.11973687, 0.        , 0.        ,\n",
              "        0.25400025, 0.04490133],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.03126527, 0.        , 0.41871789, 0.        , 0.0362977 ,\n",
              "        0.06579517, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.06963106, 0.        , 0.04652421,\n",
              "        0.        , 0.        , 0.05802589, 0.        , 0.        ,\n",
              "        0.        , 0.        ],\n",
              "       [0.        , 0.08347839, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.41871789, 0.        , 0.        , 0.05572782,\n",
              "        0.        , 0.        , 0.04583492, 0.        , 0.        ,\n",
              "        0.05345225, 0.        , 0.        , 0.        , 0.07142857,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        ],\n",
              "       [0.04012862, 0.09769344, 0.        , 0.        , 0.09567297,\n",
              "        0.48685383, 0.0362977 , 0.05572782, 0.        , 0.        ,\n",
              "        0.23643312, 0.20851441, 0.21455956, 0.20064309, 0.        ,\n",
              "        0.08340577, 0.        , 0.2502173 , 0.        , 0.05572782,\n",
              "        0.08025724, 0.        , 0.20851441, 0.        , 0.        ,\n",
              "        0.29488391, 0.        ],\n",
              "       [0.14547859, 0.11805627, 0.        , 0.        , 0.26013299,\n",
              "        0.06788442, 0.06579517, 0.        , 0.        , 0.23643312,\n",
              "        0.        , 0.2362278 , 0.2268713 , 0.32732684, 0.        ,\n",
              "        0.        , 0.        , 0.03779645, 0.        , 0.        ,\n",
              "        0.0727393 , 0.        , 0.25197632, 0.        , 0.        ,\n",
              "        0.26726124, 0.        ],\n",
              "       [0.04811252, 0.11713032, 0.        , 0.        , 0.11470787,\n",
              "        0.08980265, 0.        , 0.        , 0.        , 0.20851441,\n",
              "        0.2362278 , 0.        , 0.12862394, 0.14433757, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.09622504, 0.        , 0.16666667, 0.        , 0.09449112,\n",
              "        0.1767767 , 0.0625    ],\n",
              "       [0.06600984, 0.08035074, 0.        , 0.        , 0.11803342,\n",
              "        0.18481233, 0.        , 0.04583492, 0.        , 0.21455956,\n",
              "        0.2268713 , 0.12862394, 0.        , 0.23103443, 0.        ,\n",
              "        0.13719887, 0.        , 0.10289915, 0.        , 0.        ,\n",
              "        0.03300492, 0.        , 0.11433239, 0.        , 0.        ,\n",
              "        0.24253563, 0.        ],\n",
              "       [0.11111111, 0.09016696, 0.        , 0.05143445, 0.30905755,\n",
              "        0.06913011, 0.        , 0.        , 0.        , 0.20064309,\n",
              "        0.32732684, 0.14433757, 0.23103443, 0.        , 0.        ,\n",
              "        0.07698004, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.03703704, 0.        , 0.19245009, 0.05555556, 0.        ,\n",
              "        0.27216553, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        ],\n",
              "       [0.11547005, 0.        , 0.        , 0.05345225, 0.09176629,\n",
              "        0.07184212, 0.        , 0.05345225, 0.        , 0.08340577,\n",
              "        0.        , 0.        , 0.13719887, 0.07698004, 0.        ,\n",
              "        0.        , 0.        , 0.16      , 0.12060454, 0.        ,\n",
              "        0.07698004, 0.        , 0.        , 0.05773503, 0.        ,\n",
              "        0.07071068, 0.05      ],\n",
              "       [0.06804138, 0.05521576, 0.35355339, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.06804138, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.25144742, 0.06963106, 0.        , 0.        , 0.2502173 ,\n",
              "        0.03779645, 0.        , 0.10289915, 0.        , 0.        ,\n",
              "        0.16      , 0.        , 0.        , 0.06030227, 0.        ,\n",
              "        0.03849002, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.12060454, 0.        , 0.06030227, 0.        , 0.0805823 ,\n",
              "        0.        , 0.        , 0.        , 0.17407766, 0.        ,\n",
              "        0.        , 0.        ],\n",
              "       [0.        , 0.04173919, 0.        , 0.07142857, 0.        ,\n",
              "        0.        , 0.04652421, 0.07142857, 0.        , 0.05572782,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.0805823 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.07715167, 0.        ,\n",
              "        0.        , 0.        ],\n",
              "       [0.03703704, 0.        , 0.        , 0.1028689 , 0.        ,\n",
              "        0.06913011, 0.        , 0.        , 0.        , 0.08025724,\n",
              "        0.0727393 , 0.09622504, 0.03300492, 0.03703704, 0.        ,\n",
              "        0.07698004, 0.06804138, 0.03849002, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.13608276, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        ],\n",
              "       [0.06415003, 0.10411584, 0.        , 0.        , 0.22941573,\n",
              "        0.11973687, 0.05802589, 0.        , 0.        , 0.20851441,\n",
              "        0.25197632, 0.16666667, 0.11433239, 0.19245009, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.23570226, 0.16666667],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.05555556, 0.        ,\n",
              "        0.05773503, 0.        , 0.        , 0.17407766, 0.07715167,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.09449112, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.09449112],\n",
              "       [0.06804138, 0.11043153, 0.        , 0.09449112, 0.16222142,\n",
              "        0.25400025, 0.        , 0.        , 0.        , 0.29488391,\n",
              "        0.26726124, 0.1767767 , 0.24253563, 0.27216553, 0.        ,\n",
              "        0.07071068, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.13608276, 0.        , 0.23570226, 0.        , 0.        ,\n",
              "        0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.05735393,\n",
              "        0.04490133, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.0625    , 0.        , 0.        , 0.        ,\n",
              "        0.05      , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.16666667, 0.        , 0.09449112,\n",
              "        0.        , 0.        ]])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_similarity_martix = build_similarity_matrix(text, stop_words=stopwords.words('english'))\n",
        "sentence_similarity_martix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LSDioITBrGp",
        "outputId": "83ee255f-fe20-4fc7-992f-f161262682c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 0.03273091522421835,\n",
              " 1: 0.03666725498531675,\n",
              " 2: 0.02400955938727758,\n",
              " 3: 0.01805605209893996,\n",
              " 4: 0.05061174265286081,\n",
              " 5: 0.055382089622588206,\n",
              " 6: 0.030355735096742772,\n",
              " 7: 0.030961023532759067,\n",
              " 8: 0.006134969325153374,\n",
              " 9: 0.07932144283189654,\n",
              " 10: 0.06856682994137366,\n",
              " 11: 0.05433795109405862,\n",
              " 12: 0.058360292719297074,\n",
              " 13: 0.0657056670360068,\n",
              " 14: 0.006134969325153374,\n",
              " 15: 0.04510370780518802,\n",
              " 16: 0.03241179332597175,\n",
              " 17: 0.03424944229889421,\n",
              " 18: 0.02385326766728013,\n",
              " 19: 0.023472688977320296,\n",
              " 20: 0.032077947178768065,\n",
              " 21: 0.006134969325153374,\n",
              " 22: 0.0589366944991609,\n",
              " 23: 0.020946233388572714,\n",
              " 24: 0.012394326582128409,\n",
              " 25: 0.0713482514716912,\n",
              " 26: 0.021734182606227823}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Fungsi untuk menghasilkan skor PageRank untuk setiap kalimat\n",
        "sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
        "scores = nx.pagerank(sentence_similarity_graph)\n",
        "scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLn_8RrgX6E-"
      },
      "source": [
        "Kita dapat memperoleh skor PageRank yang menunjukkan tingkat pentingnya setiap kalimat dalam konteks kemiripan kalimat. Skor ini dapat digunakan untuk mengidentifikasi kalimat-kalimat yang lebih penting atau relevan dalam teks, seperti kalimat-kalimat yang paling mewakili topik atau kalimat-kalimat yang memiliki dampak lebih besar dalam pemahaman teks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1j5G77H8xZm"
      },
      "outputs": [],
      "source": [
        "#Fungsi untuk menghasilkan summary text\n",
        "def generate_summary(file_name, top_n):\n",
        "    stop_words = stopwords.words('english')\n",
        "    summarize_text = []\n",
        "\n",
        "    #Baca teks dan pisahkan\n",
        "    sentences =  read_article(file_name)\n",
        "\n",
        "    #Hasilkan Similarity Martix di seluruh kalimat\n",
        "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
        "\n",
        "    #Beri peringkat kalimat dalam kesamaan martiks\n",
        "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
        "    scores = nx.pagerank(sentence_similarity_graph)\n",
        "\n",
        "    #Urutkan peringkat dan pilih kalimat teratas\n",
        "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
        "    print(\"\\nIndexes of top ranked_sentence order are \", ranked_sentence)\n",
        "\n",
        "    for i in range(top_n):\n",
        "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
        "\n",
        "    #Output dari summarize text\n",
        "    print(\"\\nSummarize Text: \\n\", \". \".join(summarize_text))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0V0Q0Py8xZm",
        "outputId": "db2ed92b-502d-48c3-bb7f-05b416079ae9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The transfer of vocational education and training (VET) systems is currently an important topic in international debates (Davoine and Deitmer Citation2020; Maurer and Gonon Citation2014a; Valiente and Scandurra Citation2017; Allais Citation2010; King Citation2014; McGrath Citation2002)\n",
            "The reasons given for policy transfer in the VET sector are complex and include aspects like (youth) unemployment reduction, poverty reduction, equipping skilled workers and increasing economic growth (Wiriadidjaja, Andriasanti, and Jane Citation2019; Stockmann Citation2019; France Diplomacy Citation2019; Bank et al\n",
            "Citation2015)\n",
            "However, surprisingly little recent research has explored issues such as practicability, successes achieved, problems encountered, and long-term effects\n",
            "Scholars are more likely to focus on the theoretical basis for training transfer (Dolowitz and Marsh Citation2000), or on options for transfer at a more intermediate level of abstraction (Gonon Citation2014)\n",
            "Policy transfer can be defined in various ways, and this can be confusing  partly due to the nuances involved of policy transfer, and partly due to the fact that different definitions have emerged within different academic disciplines\n",
            "For example, the terms policy learning and policy transfer are used in political science, while policy diffusion and policy reception are used in sociology, social anthropology, and historical studies\n",
            "The terms policy borrowing and policy lending originated in the comparative educational sciences (Finegold et al\n",
            "Citation1993; Steiner-Khamsi Citation2012)\n",
            "Terms such as transfer, export, and policy borrowing or learning are also imprecisely defined or controversial, partly because different disciplines use different metaphors for the policy transfer process\n",
            "Policy transfer is commonly used in the international and interdisciplinary context: this term covers the transfer of education, but it also implies the transfer of procedures, measures, strategies, and concepts in the broadest sense (Rose Citation1991)\n",
            "The following discussion is not limited to a narrow conceptualisation of policy at the systemic level; it also focuses on micro-political transfer activities that are highly relevant to VET\n",
            "It will build on Hulmes (Citation2005) ideas about the movement of ideas and practices and apply the term policy in its broadest sense.Footnote1 It will demonstrate that policy transfer as it relates to VETFootnote2 is not the exclusive domain of scholars working in international comparative VET research; it is related to work being conducted in various disciplines and from different perspectives\n",
            "However, scholars working in all disciplines are guided by the same basic questions related to the dimensions of the motives of the transfer, the actors involved, the transfer process, the object of the transfer and the degree of success of the transfer (e.g\n",
            "Rahimi and Smith Citation2017)\n",
            "In other words, what is transferred, how, and with what results, and which factors are decisive? This literature review synthesises the findings from different disciplines, exploring differences and similarities; the results provide important lessons for scholars working in comparative vocational training research\n",
            "We have selected a narrative approach to investigate this complex topic (Ferrari Citation2015)\n",
            "This technique is particularly useful in this context because it can incorporate literature from different countries and different languages in appropriate and meaningful ways, despite the different terminology used (Hammersley Citation2006)\n",
            "This extensive literature review includes contributions from scientific journals, anthologies, and monographs from recognised institutions\n",
            "It does not include project reports or other reports on single implementation at the micro-level, because they have little value in terms of scientific generalisation\n",
            "We searched electronic databases, and also conducted research in libraries and by applying a snowballing strategy, to find research published in English and also German, due to the special importance of the topic in German-speaking countries (e.g\n",
            "iMove Citation2020)\n",
            "We have included theoretical and conceptual contributions, as well as empirical studies on policy transfer\n",
            "All publications were assessed for quality, including the standards of scientific work, such as the review process, quality of citation, etc\n",
            "Relevant themes were identified using inductive category formation\n",
            "The next sections introduce policy transfer research from various disciplines\n",
            "Each discipline is discussed separately  first by outlining the specific focus of each discipline, followed by an exploration of the relevant theoretical, conceptual and empirical results\n",
            "Finally, we synthesise the results from all disciplines to derive conclusions and possible directions for future research.\n",
            "\n",
            "Indexes of top ranked_sentence order are  [(0.07932144283189654, ['Terms', 'such', 'as', 'transfer,', 'export,', 'and', 'policy', 'borrowing', 'or', 'learning', 'are', 'also', 'imprecisely', 'defined', 'or', 'controversial,', 'partly', 'because', 'different', 'disciplines', 'use', 'different', 'metaphors', 'for', 'the', 'policy', 'transfer', 'process']), (0.0713482514716912, ['The', 'next', 'sections', 'introduce', 'policy', 'transfer', 'research', 'from', 'various', 'disciplines']), (0.06856682994137366, ['Policy', 'transfer', 'is', 'commonly', 'used', 'in', 'the', 'international', 'and', 'interdisciplinary', 'context:', 'this', 'term', 'covers', 'the', 'transfer', 'of', 'education,', 'but', 'it', 'also', 'implies', 'the', 'transfer', 'of', 'procedures,', 'measures,', 'strategies,', 'and', 'concepts', 'in', 'the', 'broadest', 'sense', '(Rose', 'Citation1991)']), (0.0657056670360068, ['However,', 'scholars', 'working', 'in', 'all', 'disciplines', 'are', 'guided', 'by', 'the', 'same', 'basic', 'questions', 'related', 'to', 'the', 'dimensions', 'of', 'the', 'motives', 'of', 'the', 'transfer,', 'the', 'actors', 'involved,', 'the', 'transfer', 'process,', 'the', 'object', 'of', 'the', 'transfer', 'and', 'the', 'degree', 'of', 'success', 'of', 'the', 'transfer', '(e.g']), (0.0589366944991609, ['We', 'have', 'included', 'theoretical', 'and', 'conceptual', 'contributions,', 'as', 'well', 'as', 'empirical', 'studies', 'on', 'policy', 'transfer']), (0.058360292719297074, ['It', 'will', 'build', 'on', 'Hulmes', '(Citation2005)', 'ideas', 'about', 'the', 'movement', 'of', 'ideas', 'and', 'practices', 'and', 'apply', 'the', 'term', 'policy', 'in', 'its', 'broadest', 'sense.Footnote1', 'It', 'will', 'demonstrate', 'that', 'policy', 'transfer', 'as', 'it', 'relates', 'to', 'VETFootnote2', 'is', 'not', 'the', 'exclusive', 'domain', 'of', 'scholars', 'working', 'in', 'international', 'comparative', 'VET', 'research;', 'it', 'is', 'related', 'to', 'work', 'being', 'conducted', 'in', 'various', 'disciplines', 'and', 'from', 'different', 'perspectives']), (0.055382089622588206, ['Policy', 'transfer', 'can', 'be', 'defined', 'in', 'various', 'ways,', 'and', 'this', 'can', 'be', 'confusing', '', 'partly', 'due', 'to', 'the', 'nuances', 'involved', 'of', 'policy', 'transfer,', 'and', 'partly', 'due', 'to', 'the', 'fact', 'that', 'different', 'definitions', 'have', 'emerged', 'within', 'different', 'academic', 'disciplines']), (0.05433795109405862, ['The', 'following', 'discussion', 'is', 'not', 'limited', 'to', 'a', 'narrow', 'conceptualisation', 'of', 'policy', 'at', 'the', 'systemic', 'level;', 'it', 'also', 'focuses', 'on', 'micro-political', 'transfer', 'activities', 'that', 'are', 'highly', 'relevant', 'to', 'VET']), (0.05061174265286081, ['Scholars', 'are', 'more', 'likely', 'to', 'focus', 'on', 'the', 'theoretical', 'basis', 'for', 'training', 'transfer', '(Dolowitz', 'and', 'Marsh', 'Citation2000),', 'or', 'on', 'options', 'for', 'transfer', 'at', 'a', 'more', 'intermediate', 'level', 'of', 'abstraction', '(Gonon', 'Citation2014)']), (0.04510370780518802, ['In', 'other', 'words,', 'what', 'is', 'transferred,', 'how,', 'and', 'with', 'what', 'results,', 'and', 'which', 'factors', 'are', 'decisive?', 'This', 'literature', 'review', 'synthesises', 'the', 'findings', 'from', 'different', 'disciplines,', 'exploring', 'differences', 'and', 'similarities;', 'the', 'results', 'provide', 'important', 'lessons', 'for', 'scholars', 'working', 'in', 'comparative', 'vocational', 'training', 'research']), (0.03666725498531675, ['The', 'reasons', 'given', 'for', 'policy', 'transfer', 'in', 'the', 'VET', 'sector', 'are', 'complex', 'and', 'include', 'aspects', 'like', '(youth)', 'unemployment', 'reduction,', 'poverty', 'reduction,', 'equipping', 'skilled', 'workers', 'and', 'increasing', 'economic', 'growth', '(Wiriadidjaja,', 'Andriasanti,', 'and', 'Jane', 'Citation2019;', 'Stockmann', 'Citation2019;', 'France', 'Diplomacy', 'Citation2019;', 'Bank', 'et', 'al']), (0.03424944229889421, ['This', 'technique', 'is', 'particularly', 'useful', 'in', 'this', 'context', 'because', 'it', 'can', 'incorporate', 'literature', 'from', 'different', 'countries', 'and', 'different', 'languages', 'in', 'appropriate', 'and', 'meaningful', 'ways,', 'despite', 'the', 'different', 'terminology', 'used', '(Hammersley', 'Citation2006)']), (0.03273091522421835, ['\\ufeffThe', 'transfer', 'of', 'vocational', 'education', 'and', 'training', '(VET)', 'systems', 'is', 'currently', 'an', 'important', 'topic', 'in', 'international', 'debates', '(Davoine', 'and', 'Deitmer', 'Citation2020;', 'Maurer', 'and', 'Gonon', 'Citation2014a;', 'Valiente', 'and', 'Scandurra', 'Citation2017;', 'Allais', 'Citation2010;', 'King', 'Citation2014;', 'McGrath', 'Citation2002)']), (0.03241179332597175, ['We', 'have', 'selected', 'a', 'narrative', 'approach', 'to', 'investigate', 'this', 'complex', 'topic', '(Ferrari', 'Citation2015)']), (0.032077947178768065, ['We', 'searched', 'electronic', 'databases,', 'and', 'also', 'conducted', 'research', 'in', 'libraries', 'and', 'by', 'applying', 'a', 'snowballing', 'strategy,', 'to', 'find', 'research', 'published', 'in', 'English', 'and', 'also', 'German,', 'due', 'to', 'the', 'special', 'importance', 'of', 'the', 'topic', 'in', 'German-speaking', 'countries', '(e.g']), (0.030961023532759067, ['The', 'terms', 'policy', 'borrowing', 'and', 'policy', 'lending', 'originated', 'in', 'the', 'comparative', 'educational', 'sciences', '(Finegold', 'et', 'al']), (0.030355735096742772, ['For', 'example,', 'the', 'terms', 'policy', 'learning', 'and', 'policy', 'transfer', 'are', 'used', 'in', 'political', 'science,', 'while', 'policy', 'diffusion', 'and', 'policy', 'reception', 'are', 'used', 'in', 'sociology,', 'social', 'anthropology,', 'and', 'historical', 'studies']), (0.02400955938727758, ['Citation2015)']), (0.02385326766728013, ['This', 'extensive', 'literature', 'review', 'includes', 'contributions', 'from', 'scientific', 'journals,', 'anthologies,', 'and', 'monographs', 'from', 'recognised', 'institutions']), (0.023472688977320296, ['It', 'does', 'not', 'include', 'project', 'reports', 'or', 'other', 'reports', 'on', 'single', 'implementation', 'at', 'the', 'micro-level,', 'because', 'they', 'have', 'little', 'value', 'in', 'terms', 'of', 'scientific', 'generalisation']), (0.021734182606227823, ['Each', 'discipline', 'is', 'discussed', 'separately', '', 'first', 'by', 'outlining', 'the', 'specific', 'focus', 'of', 'each', 'discipline,', 'followed', 'by', 'an', 'exploration', 'of', 'the', 'relevant', 'theoretical,', 'conceptual', 'and', 'empirical', 'results']), (0.020946233388572714, ['All', 'publications', 'were', 'assessed', 'for', 'quality,', 'including', 'the', 'standards', 'of', 'scientific', 'work,', 'such', 'as', 'the', 'review', 'process,', 'quality', 'of', 'citation,', 'etc']), (0.01805605209893996, ['However,', 'surprisingly', 'little', 'recent', 'research', 'has', 'explored', 'issues', 'such', 'as', 'practicability,', 'successes', 'achieved,', 'problems', 'encountered,', 'and', 'long-term', 'effects']), (0.012394326582128409, ['Relevant', 'themes', 'were', 'identified', 'using', 'inductive', 'category', 'formation']), (0.006134969325153374, ['iMove', 'Citation2020)']), (0.006134969325153374, ['Rahimi', 'and', 'Smith', 'Citation2017)']), (0.006134969325153374, ['Citation1993;', 'Steiner-Khamsi', 'Citation2012)'])]\n",
            "\n",
            "Summarize Text: \n",
            " Terms such as transfer, export, and policy borrowing or learning are also imprecisely defined or controversial, partly because different disciplines use different metaphors for the policy transfer process. The next sections introduce policy transfer research from various disciplines. Policy transfer is commonly used in the international and interdisciplinary context: this term covers the transfer of education, but it also implies the transfer of procedures, measures, strategies, and concepts in the broadest sense (Rose Citation1991)\n"
          ]
        }
      ],
      "source": [
        "generate_summary( \"data_4C.txt\", 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om1EhPKakXh_"
      },
      "source": [
        "**Hasil Text Summarization:**\n",
        "\n",
        "Terms such as transfer, export, and policy borrowing or learning are also imprecisely defined or controversial, partly because different disciplines use different metaphors for the policy transfer process. The next sections introduce policy transfer research from various disciplines. Policy transfer is commonly used in the international and interdisciplinary context: this term covers the transfer of education, but it also implies the transfer of procedures, measures, strategies, and concepts in the broadest sense (Rose Citation1991)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
